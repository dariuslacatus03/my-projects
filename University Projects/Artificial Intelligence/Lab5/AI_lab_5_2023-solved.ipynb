{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8210b19",
   "metadata": {},
   "source": [
    "## A.I. Assignment 5\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Get more familiar with tensors in pytorch \n",
    "* Create a simple multilayer perceptron model with pytorch\n",
    "* Visualise the parameters\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Build a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n",
    "\n",
    "Create at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n",
    "\n",
    "Display for the best one the weights for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3614e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5ee7e7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/5000], Loss: 0.4139\n",
      "Epoch [1000/5000], Loss: 0.3802\n",
      "Epoch [1500/5000], Loss: 0.3687\n",
      "Epoch [2000/5000], Loss: 0.3629\n",
      "Epoch [2500/5000], Loss: 0.3595\n",
      "Epoch [3000/5000], Loss: 0.3573\n",
      "Epoch [3500/5000], Loss: 0.3557\n",
      "Epoch [4000/5000], Loss: 0.3545\n",
      "Epoch [4500/5000], Loss: 0.3536\n",
      "Epoch [5000/5000], Loss: 0.3529\n",
      "Accuracy: 100%\n",
      "Perceptron([0, 0]): tensor([0.0127], grad_fn=<SigmoidBackward0>)\n",
      "Perceptron([0, 1]): tensor([0.5040], grad_fn=<SigmoidBackward0>)\n",
      "Perceptron([1, 0]): tensor([0.5040], grad_fn=<SigmoidBackward0>)\n",
      "Perceptron([1, 1]): tensor([0.9877], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Input data for Bit Addition gate\n",
    "input_data = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "# Labels for Bit Addition gate\n",
    "labels = torch.tensor([[0], [0.5], [0.5], [1]], dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Define the Perceptron class\n",
    "class MyPerceptron1(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MyPerceptron1, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the stochastic gradient descent optimizer\n",
    "perceptron = MyPerceptron1(input_dim=2)  # Input dimension for bit addition gate is 2\n",
    "\n",
    "# Define the optimizer and the binary cross-entropy loss function.\n",
    "optimizer = optim.SGD(perceptron.parameters(), lr=0.1)\n",
    "\n",
    "loss_criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "\n",
    "# Train the Perceptron model\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = perceptron(input_data)\n",
    "    # Calculate loss\n",
    "    loss = loss_criterion(outputs, labels)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Calculate predictions\n",
    "predictions = perceptron(input_data)\n",
    "\n",
    "correct_predictions = 0\n",
    "threshold = 0.1\n",
    "\n",
    "# Evaluate the model and calculate accuracy\n",
    "for i, label in enumerate(labels):\n",
    "    prediction = predictions[i]\n",
    "    # Check if the prediction is within the threshold of the label\n",
    "    if abs(prediction - label) < threshold:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = correct_predictions / len(labels)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy: {accuracy*100:.0f}%')\n",
    "\n",
    "\n",
    "print(f'Perceptron([0, 0]): {perceptron(input_data[0])}')\n",
    "print(f'Perceptron([0, 1]): {perceptron(input_data[1])}')\n",
    "print(f'Perceptron([1, 0]): {perceptron(input_data[2])}')\n",
    "print(f'Perceptron([1, 1]): {perceptron(input_data[3])}')\n",
    "\n",
    "print(input_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "665ae958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/5000], Loss: 0.5337\n",
      "Epoch [1000/5000], Loss: 0.4173\n",
      "Epoch [1500/5000], Loss: 0.3823\n",
      "Epoch [2000/5000], Loss: 0.3688\n",
      "Epoch [2500/5000], Loss: 0.3622\n",
      "Epoch [3000/5000], Loss: 0.3584\n",
      "Epoch [3500/5000], Loss: 0.3560\n",
      "Epoch [4000/5000], Loss: 0.3544\n",
      "Epoch [4500/5000], Loss: 0.3532\n",
      "Epoch [5000/5000], Loss: 0.3523\n",
      "Accuracy: 100%\n",
      "Perceptron([0, 0]): tensor([0.0105], grad_fn=<SigmoidBackward0>)\n",
      "Perceptron([0, 1]): tensor([0.5012], grad_fn=<SigmoidBackward0>)\n",
      "Perceptron([1, 0]): tensor([0.5013], grad_fn=<SigmoidBackward0>)\n",
      "Perceptron([1, 1]): tensor([0.9877], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "#model1 = nn.Sequential(OrderedDict([\n",
    "#    ('hidden', nn.\n",
    "#]))\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Input data for Bit Addition gate\n",
    "input_data = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "# Labels for Bit Addition gate\n",
    "labels = torch.tensor([[0], [0.5], [0.5], [1]], dtype=torch.float32)\n",
    "\n",
    "#Define hidden_size\n",
    "\n",
    "# Define the Perceptron class\n",
    "class MyPerceptron2(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size):\n",
    "        super(MyPerceptron2, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, 1);\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.layer2(torch.sigmoid(self.layer1(x))))\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the stochastic gradient descent optimizer\n",
    "perceptron = MyPerceptron2(input_dim=2, hidden_size=4)  # Input dimension for bit addition gate is 2\n",
    "\n",
    "# Define the optimizer and the binary cross-entropy loss function.\n",
    "optimizer = optim.SGD(perceptron.parameters(), lr=0.1)\n",
    "\n",
    "loss_criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "\n",
    "# Train the Perceptron model\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = perceptron(input_data)\n",
    "    # Calculate loss\n",
    "    loss = loss_criterion(outputs, labels)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Calculate predictions\n",
    "predictions = perceptron(input_data)\n",
    "\n",
    "correct_predictions = 0\n",
    "threshold = 0.1\n",
    "\n",
    "# Evaluate the model and calculate accuracy\n",
    "for i, label in enumerate(labels):\n",
    "    prediction = predictions[i]\n",
    "    # Check if the prediction is within the threshold of the label\n",
    "    if abs(prediction - label) < threshold:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = correct_predictions / len(labels)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy: {accuracy*100:.0f}%')\n",
    "\n",
    "\n",
    "print(f'Perceptron([0, 0]): {perceptron(input_data[0])}')\n",
    "print(f'Perceptron([0, 1]): {perceptron(input_data[1])}')\n",
    "print(f'Perceptron([1, 0]): {perceptron(input_data[2])}')\n",
    "print(f'Perceptron([1, 1]): {perceptron(input_data[3])}')\n",
    "\n",
    "print(input_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e26f0d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/5000], Loss: 0.0861\n",
      "Epoch [1000/5000], Loss: 0.0431\n",
      "Epoch [1500/5000], Loss: 0.0199\n",
      "Epoch [2000/5000], Loss: 0.0109\n",
      "Epoch [2500/5000], Loss: 0.0069\n",
      "Epoch [3000/5000], Loss: 0.0049\n",
      "Epoch [3500/5000], Loss: 0.0037\n",
      "Epoch [4000/5000], Loss: 0.0029\n",
      "Epoch [4500/5000], Loss: 0.0024\n",
      "Epoch [5000/5000], Loss: 0.0020\n",
      "Accuracy: 100%\n",
      "Perceptron([0, 0]): tensor([0.0576], grad_fn=<SigmoidBackward0>)\n",
      "Perceptron([0, 1]): tensor([0.5037], grad_fn=<SigmoidBackward0>)\n",
      "Perceptron([1, 0]): tensor([0.5035], grad_fn=<SigmoidBackward0>)\n",
      "Perceptron([1, 1]): tensor([0.9315], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "#model1 = nn.Sequential(OrderedDict([\n",
    "#    ('hidden', nn.\n",
    "#]))\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Input data for Bit Addition gate\n",
    "input_data = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "# Labels for Bit Addition gate\n",
    "labels = torch.tensor([[0], [0.5], [0.5], [1]], dtype=torch.float32)\n",
    "\n",
    "#Define hidden_size\n",
    "\n",
    "# Define the Perceptron class\n",
    "class MyPerceptron3(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size):\n",
    "        super(MyPerceptron3, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, 1);\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.layer2(torch.sigmoid(self.layer1(x))))\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the stochastic gradient descent optimizer\n",
    "perceptron = MyPerceptron3(input_dim=2, hidden_size=4)  # Input dimension for bit addition gate is 2\n",
    "\n",
    "# Define the optimizer and the binary cross-entropy loss function.\n",
    "optimizer = optim.SGD(perceptron.parameters(), lr=0.1)\n",
    "\n",
    "loss_criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "# Train the Perceptron model\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = perceptron(input_data)\n",
    "    # Calculate loss\n",
    "    loss = loss_criterion(outputs, labels)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Calculate predictions\n",
    "predictions = perceptron(input_data)\n",
    "\n",
    "correct_predictions = 0\n",
    "threshold = 0.1\n",
    "\n",
    "# Evaluate the model and calculate accuracy\n",
    "for i, label in enumerate(labels):\n",
    "    prediction = predictions[i]\n",
    "    # Check if the prediction is within the threshold of the label\n",
    "    if abs(prediction - label) < threshold:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = correct_predictions / len(labels)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy: {accuracy*100:.0f}%')\n",
    "\n",
    "\n",
    "print(f'Perceptron([0, 0]): {perceptron(input_data[0])}')\n",
    "print(f'Perceptron([0, 1]): {perceptron(input_data[1])}')\n",
    "print(f'Perceptron([1, 0]): {perceptron(input_data[2])}')\n",
    "print(f'Perceptron([1, 1]): {perceptron(input_data[3])}')\n",
    "\n",
    "print(input_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a64c94-3d91-4e15-b526-725bb15e9135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
